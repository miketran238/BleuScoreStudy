        \documentclass[sigconf,review, anonymous]{acmart}
        \acmConference[ESEC/FSE 2018]{The 26th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering}{4-9 November, 2018}{Lake Buena Vista, Florida, United States}

\usepackage{booktabs} % For formal tables


\begin{document}
\title{Bleu Score Study}



\author{Ngoc M. Tran}
\orcid{1234-5678-9012}
\affiliation{%
  \institution{University of  Texas at Dallas}
  \streetaddress{800 E. Campbell Rd}
  \city{Richardson}
  \state{Texas}
  \postcode{75080}
}
\email{ngoctran@utdallas.edu}




\begin{abstract}
Machine translation (MT) is a fast growing sub-field of computational linguistic. Until now, the most popular automatic metrics to measure the quality of MT is Bleu score. Lately, MT along with its Bleu metric has been applied to many Software Engineering(SE) tasks. In this paper, we studied Bleu score to validate its suitability for software engineering tasks. We showed that Bleu score does not reflect translation quality due to its weak relation with semantic meaning of the translated source codes. Specifically, an increase in Bleu score does not guarantee an improved in translation quality, and a good translation may have fluctuated Bleu score.  
\footnote{More abstract}
\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below.
%


\keywords{ACM proceedings, \LaTeX, text tagging}


\maketitle

\input{body}

\bibliographystyle{ACM-Reference-Format}
\bibliography{reference}

\end{document}
