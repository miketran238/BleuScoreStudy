\subsection{Metrics}

\emph{1.} \textbf{Semantic Score:} To determine semantic similarity score between pair of methods, we manually scored each pair from 0 to 6 based on the human effort to fix a translated method to a referenced one. Specifically, we list the criteria to score in Table \ref{table:criteria} with a score of 0 means the pair of methods are totally different, and a score of 6 means they are totally the same. Scoring also follows the following principles: 1. An effort to fix a syntactical error (misplacing a semi-colon, parenthesis...) has less weight than an effort to fix a semantical error (wrong branch, wrong function call...). 2. A fix that requires adding sources code has more weight than one that requires removing/replacing. 3. A fix for user-defined program elements (identifier, simple name, method name) is more 'pricey' than a fix for keyword (this, if, for...). Example (of scores 1,3,5). 

Since our dataset contains a large number of pairs of methods, it would be impossible to manually evaluate all of them. Hence, we took a sample from our population of total 34,209 pairs. According to \cite{website}, our sample size is 375 with confidence level of $95\%$ and margin of error $5\%$. 
(... Formula?). After we manually scored 375 pairs of methods, we normalized them on 0-1 range.

\emph{2.} \textbf{String Edit Distance (SED):} This metric measures
effort that a user must edit in term of the code tokens
that need to be deleted/added in order to transform the
resulting code into the correct one. It is computed as:  $SED = \frac{EditDistance\left(s_R, s_T\right)}{length\left(s_R\right)}$ where $EditDistance\left(s_R, s_T\right)$ is the editing distance between each pair of the reference method $s_R$ and the translated method $s_T$; and the denominator is the total length of the referenced method. The metrics is also normalized in 0-1 range.

\emph{3.} \textbf{Tree Edit Distance (TREED):} This metric measures the difference between the Abstract Syntax Trees (AST) of referenced method and translated method. Specifically, the tree edit distance between two trees is calculated by number of operations (add/delete/replace/move) to make them identical. \cite{algorithm}. 
It is computed as:  $TREED = \frac{TreeEditDistance\left(AST_R, AST_T\right)}{CountNodes \left(AST_R\right)}$ where $TreeEditDistance\left(AST_R, AST_T\right)$ is the editing distance between two trees of referenced method $AST_R$ and the translated method $AST_T$; and the denominator is the total nodes in the tree of the referenced method.  The metrics is also normalized in 0-1 range.

\begin{table}
\begin{tabular}{|p{0.5cm}|p{1.5cm}|p{5cm}|}
\hline
Score & Description & Effort to fix \\
\hline
0 & Totally Difference & Re-write the whole method \\
1 & Mostly Difference & The 2 methods are totally different in term of structure, but some statements are re-usabled. \\
2 & Quite Difference & The 2 methods are different in term of structure, but still share some common sub-structures. There are also different program elements. \\
3 & Average & About half of the method is correct. The other half needs to be re-written. \\
4 & Quite the Same & The 2 methods are mostly identical in term of structure, but there are some different branches. Some variables/function calls and literal are different.\\
5 & Mostly the Same & The 2 methods are identical in term of structure, but a small number of variables/function calls/literal are different \\
6 & Totally the Same & Do not need to fix anything \\
\hline
\end{tabular}
\caption{Manual Semantic Score Criteria}
\label{table:criteria}
\end{table}
