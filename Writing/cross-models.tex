\subsection{The Use of BLEU in Comparing Models}
\subsubsection{Theoretical Models}
To prove the second part of our hypothesis, we conduct study to see if an improvement in BLEU score over models reflects the improvement in translation quality represented by human judgments of semantic score. For a same set of 375 original Java methods, the two models mppSMT and mppSMT2 generates two sets of 375 translated methods. Each set has its own BLEU scores and Semantic scores. 
From the 375 pairs, we have 73 pairs that have identical BLEU scores but are different in term of lexical. 26 out of 73 (\textbf{35\%}) have lower semantic score. On average, semantic score of model mppSMT2 is lower than mppSMT's by 0.16. Given that our semantic scores have only 5 pivots range from 0 to 1, a deduction of 0.16 is a large margin as it nearly reduces the semantic score by one pivot point.  
The model mppSMT2 would swap the positions of incorrect phrases in term of lexical. However, those phrases may still have semantic information as the model mppSMT is capable of produce code that are semantically correct but lexically incorrect. There are many cases that they are semantically incorrect but still help the whole translated code syntactically correct or provide users with good starting point for the migration task. We have showed that a theoretical model can achieve identical BLEU score but has lower translation quality compared to another. 
\subsubsection{Practical Models}
Using the same experiment set up, we have two sets of 375 translated methods from two models GNMT and mppSMT. From the sample, we choose pairs of results such that their GNMT's BLEU scores are higher than mppSMT's BLEU scores. There are 215 of such pairs. Among them, 79 pairs have lower semantic score. Then, we perform t-test with alpha confident level of 0.95 on that subset to see if their GNMT's semantic scores are also significantly higher or not. Our null hypothesis is: GNMT's semantic score are higher than mppSMT's one with confident level of 0.95. The results show a t-value of \textbf{-9.1} which is lower than the critical point of -1.97. It meant we would reject the null hypothesis that GNMT's semantic scores are higher than mppSMT's ones. Our result shows that an improvement in BLEU score does not lead to an improvement in translation quality. 
%To validate the use of BLEU in comparing different SMT-based code migration systems, we conduct study to see if an improvement in BLEU score over cross models reflects the improvement in translation quality represented by human judgments of semantic score between those models. For a same set of 375 original Java methods, the two models GNMT and mppSMT generates two sets of 375 translated methods. Each set has its own BLEU scores and Semantic scores.
%We prove that an improvement in BLEU score does not sufficient nor necessary lead to an improvement in semantic score by showing:
%
%1. From the sample, we choose pairs of results such that their GNMT's BLEU scores are higher than mppSMT's BLEU scores. Then, we perform t-test with alpha confident level of 0.95 on that subset to see if their GNMT's semantic scores are also higher or not. The results show a t-value of ... It meant we would reject the null hypothesis that GNMT's semantic scores are higher than mppSMT's ones. So, it can be concluded that an improvement in BLEU score is not sufficient to achieve a higher semantic score. 
%
%2.  From the sample, we choose pairs of results such that their mppSMT's semantic scores are higher than GNMT's semantic scores. Then, we perform t-test with alpha confident level of 0.95 on that subset to see if their mppSMT's BLEU scores are also higher or not. The results show a t-value of ... It meant we would reject the null hypothesis that mppSMT's BLEU scores are higher than GNMT's ones. So, it can be concluded that an improvement in BLEU score is not necessary to achieve a higher semantic score. 

%We ignored pairs of translated results if they have the same BLEU score or Semantic score (136 of the cases). For the remaining results, we found out that in \textbf{34\%} of the cases, the change in BLEU score contradicts the change in Semantic score. It means an improvement in BLEU score leads to a decrease in Semantic score and vice versa. In other words, if one function is translated by two migration models, one-third of the time, the result which has higher BLEU score actually has lower translation quality than the other.

Because of the results above, BLEU is not reliable to use in comparing different SMT-based migration models.
