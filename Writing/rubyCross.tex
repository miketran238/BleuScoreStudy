\subsubsection{The Use of RUBY in Comparing Models}
We conducted the same experiment on {\model} as we did with BLEU on cross models. 
\textbf{mppSMT vs p-mppSMT}\\
On these two models that have identical BLEU scores, {\model} is able to identify their difference in translation quality estimated by semantic similarity. Specifically, the model mppSMT's average {\model} score is higher than p-mppSMT by \textbf{0.15} which nearly equals to the difference in term of semantic score (0.17). We also perform t-test on the data set to see if there is a significant difference in {\model} scores. With confident level of 0.95, we get the p-value of reject the null hypothesis that mppSMT's {\model} score is indifferent with p-mppSMT's ones.  
%Comparing models GNMT and mppSMT, we found out that in \textbf{97.7\%} of the cases, the change in {\model} score indicates the change in the same direction for Semantic score. It means an improvement in {\model} score equivalents an improvement in Semantic scores and vice versa. More interestingly, 83 of 88 cases (\textbf{94.3\%}) if a pair of translated results have the same Semantic score, they also have identical {\model} score. 
As the results showing, {\model} is a reliable metric to use in comparing different SMT-based migration models. 	