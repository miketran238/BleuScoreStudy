\subsubsection{The use of {\model} in comparing models}
%To evaluate {\model}'s abilities in comparing the translation quality
%of models,
We performed an evaluation on RUBY being used in comparing the two
models mppSMT and p-mppSMT.
%examination to evaluate the effectiveness of {\model} in comparing
%mppSMT and p-mppSMT. 
%
Then, we also evaluated {\model} in comparing three real-world
SMT-based migration models lpSMT~\cite{fse13}, mppSMT~\cite{ase15},
and GNMT~\cite{gnmt}.  
%the effectiveness of {\model} is also evaluated in comparing several
%real-world translation models lpSMT, mppSMT and GNMT.
%
For any two models $M$ and $M'$, we proceeded as follows. First, we
performed $t$-test (at the confidence level of 95\%) with the mean
values of semantic scores on the two sets of results migrated by the
two models. We then processed $t$-test in the same manner on the two
sets of {\model}'s scores for the results migrated by the two
models. If the decision whether $M$ is better than $M'$ by {\model} is
consistent with that by the semantic scores, we consider {\model} as
effective in comparing the models.

%We use $t$-test and the mean values of semantic scores to conclude
%about the translation quality comparison between two models with a
%given confident level (95\% in our experiments).  The conclusion based
%on {\model} is also drawn in the same manner. The two conclusions will
%be checked whether consistent or not in order to confirm the
%effectiveness of {\model} in comparing these two models.


\noindent \textbf{Comparing mppSMT and p-mppSMT:} In this experiment, 
to compare the two models mppSMT and p-mppSMT, by using $t$-test, we
were able to reject the null hypothesis that \textit{the semantic
scores of two models are equal} with $p$-value of 2.81E-85. Because
the average semantic score of mppSMT is greater than p-mppSMT by
0.268, we conclude that the translation quality of mppSMT is better
than p-mppSMT based on the semantic scores.
%
To compare mppSMT and p-mppSMT using {\model}, we performed another
$t$-test with the null hypothesis that \textit{the {\model} scores of
two models are equal}. We were able to reject it with $p$-value of
7.78E-65. The confidence interval for the difference between means is
$\pm0.01$ at 95\% level of confidence. For mppSMT, the mean value of
{\model} scores is higher than that of p-mppSMT (0.258). Hence, the
conclusion that mppSMT is better than p-mppSMT is consistently stated
by {\model} and by the semantic scores.
%based on {\model} and semantic score are consistent. 
Thus, the effectiveness of {\model} in comparing
those two models
%mppSMT and p-mppSMT
is confirmed.
%{\model} is able to identify their difference 
%in translation quality estimated by semantic similarity. Specifically, the model mppSMT's 
%average {\model} score is higher than p-mppSMT by \textbf{0.258} which nearly equals 
%to the difference in term of semantic score (0.268). We also perform t-test on the data 
%set to see if there is a significant difference in 
%{\model} scores. With confident level of 0.95, we get the p-value of 7.78E-65. 
%That means, we reject the null hypothesis and conclude that mppSMT's {\model} 
%score is higher than p-mppSMT's ones.

\noindent \textbf{Comparing real-world models:}
We also made pairwise comparison among the three models
lpSMT~\cite{fse13}, mppSMT~\cite{ase15}, and GNMT~\cite{gnmt}. In our
$t$-tests, for all pairs, we were able to reject the null hypotheses
that \textit{the semantic scores of two models are equal}
and \textit{the {\model} scores of two models are equal}. When
comparing the average scores, {\model}'s decision is always consistent
with the semantic scores.
%
The results including the $p$-values and the mean values for the
translated results of the models are shown in
Tables~\ref{table:tTestResult} and~\ref{table:avgRubySem}. 
%
As seen, for all pairs of models, an improvement in {\model} scores
when comparing the models always reflects an improvement in
translation quality (represented by semantic scores). In brief, {\em
{\model} can be used in comparison SMT-based code migration models
because it reflects well the semantic scores in such~comparison}.
%
%For all pairs of models, {\model} shows consistent results with
%semantic scores. 
%For each pair of models, we perform t-test on their 
%semantic scores to test whether there is a significant difference between them. 
%If yes, then the average semantic scores are used to determine if a model has higher 
%semantic score than another. The same process is applied to {\model} score. The 
%\ref{table:rubyCross} demonstrates our result. In all the pairs, {\model} can measure 
%the difference of semantic scores between models. 
%Comparing models GNMT and mppSMT, we found out that in \textbf{97.7\%} of the cases, the change in {\model} score indicates the change in the same direction for Semantic score. It means an improvement in {\model} score equivalents an improvement in Semantic scores and vice versa. More interestingly, 83 of 88 cases (\textbf{94.3\%}) if a pair of translated results have the same Semantic score, they also have identical {\model} score. 
%As the results showing, {\model} is a reliable metric to use in comparing different SMT-based migration models. 
\begin{table}
\centering
\tabcolsep 3pt
\caption{$p$-value Results in Model Comparison}
\begin{tabular}{|c|c|c|c|}
\hline
 & GNMT \& mppSMT & lpSMT \& mppSMT & lpSMT \& GNMT \\
\hline
Semantic  & 1.70E-35 & 3.32E-4 & 3.22E-26  \\
\hline
RUBY  & 2.27E-25 & 1.10E-3 & 9.72E-26  \\

\hline
\end{tabular}
\label{table:tTestResult}
\end{table}

\begin{table}
\centering
\caption{Mean Semantic Scores and {\model} Scores}
\begin{tabular}{|c|c|c|c|}
\hline
 & GNMT & lpSMT & mppSMT \\
\hline
Semantic & 0.714 & 0.879 & 0.914  \\
\hline
{\model} & 0.743 & 0.886 & 0.905  \\
\hline
\end{tabular}
\label{table:avgRubySem}
\end{table}
