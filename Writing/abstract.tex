\begin{abstract}
Machine translation (MT) is a fast growing sub-field of computational linguistic. Until now, the most popular automatic metrics to measure the quality of MT is Bleu score. Lately, MT along with its Bleu metric has been applied to many Software Engineering(SE) tasks. In this paper, we studied Bleu score to validate its suitability for software engineering tasks. We showed that Bleu score does not reflect translation quality due to its weak relation with semantic meaning of the translated source codes. Specifically, an increase in Bleu score does not guarantee an improved in translation quality, and a good translation may have fluctuated Bleu score.  
\end{abstract}
